{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanzinser/Workspace/pytorch-tutorial/venv/lib/python3.6/site-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/juanzinser/Workspace/pytorch-tutorial/venv/lib/python3.6/site-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import squeezenet1_1\n",
    "import torch.functional as F\n",
    "import requests\n",
    "import shutil\n",
    "from io import open\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "\"\"\" Instantiate model, this downloads tje 4.7 mb  squzzene the first time it is called.\n",
    "To use with your own model, re-define your trained networks ad load weights as below\n",
    "\n",
    "checkpoint = torch.load(\"pathtosavemodel\")\n",
    "model = SimpleNet(num_classes=10)\n",
    "\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\"\"\"\n",
    "\n",
    "#squeezenet_model_path = \"/Users/juanzinser/.torch/models/squeezenet1_1-f364aa15.pth\"\n",
    "model = squeezenet1_1(pretrained=True)\n",
    "#model = squeezenet1_1()\n",
    "#checkpoint = torch.load(squeezenet_model_path)\n",
    "#model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict_image(image_path):\n",
    "    print(\"Prediction in progress\")\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Define transformations for the image, should (note that imagenet models are trained with image size 224)\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transformation(image).float()\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all images as batches\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    output = model(input)\n",
    "\n",
    "    index = output.data.numpy().argmax()\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction in progress\n",
      "Predicted Class  bicycle-built-for-two, tandem bicycle, tandem\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    imagefile = \"image.png\"\n",
    "\n",
    "    imagepath = os.path.join(os.getcwd(), imagefile)\n",
    "    # Donwload image if it doesn't exist\n",
    "    if not os.path.exists(imagepath):\n",
    "        data = requests.get(\n",
    "            \"https://github.com/OlafenwaMoses/ImageAI/raw/master/images/3.jpg\", stream=True)\n",
    "\n",
    "        with open(imagepath, \"wb\") as file:\n",
    "            shutil.copyfileobj(data.raw, file)\n",
    "\n",
    "        del data\n",
    "\n",
    "    index_file = \"imagenet1000_clsidx_to_labels.json\"\n",
    "\n",
    "    indexpath = os.path.join(os.getcwd(), index_file)\n",
    "    # Donwload class index if it doesn't exist\n",
    "    if not os.path.exists(indexpath):\n",
    "        data = requests.get('https://github.com/OlafenwaMoses/ImageAI/raw/master/imagenet_class_index.json')\n",
    "\n",
    "        with open(indexpath, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(data.text)\n",
    "\n",
    "    with open(indexpath) as f:\n",
    "        class_map = json.loads(f.read())\n",
    "\n",
    "    # run prediction function annd obtain prediccted class index\n",
    "    index = predict_image(imagepath)\n",
    "\n",
    "    prediction = class_map[str(index)]\n",
    "\n",
    "    print(\"Predicted Class \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(imagepath)\n",
    "\n",
    "# Define transformations for the image, should (note that imagenet models are trained with image size 224)\n",
    "transformation = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "image_tensor = transformation(image).float()\n",
    "\n",
    "# Add an extra batch dimension since pytorch treats all images as batches\n",
    "image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    image_tensor.cuda()\n",
    "\n",
    "# Turn the input into a Variable\n",
    "input = Variable(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "asd = model.features(input)\n",
    "print(plt.imshow(asd[0][5].detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 13, 13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
